{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede2be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_log_error as rmsle\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37592789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set from kaggle: https://www.kaggle.com/competitions/grupo-bimbo-inventory-demand/data\n",
    "\n",
    "#office\n",
    "train = pd.read_csv(\"train.csv\", usecols=['Semana', 'Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Producto_ID', 'Cliente_ID', 'Demanda_uni_equil'])\n",
    "test = pd.read_csv(\"test.csv\", usecols=['Semana', 'Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Producto_ID', 'Cliente_ID', 'id'])\n",
    "\n",
    "train = train.rename(columns={'Semana': 'Week_num',\n",
    "                              'Agencia_ID': 'Sales_Depot_ID',\n",
    "                              'Canal_ID': 'Sales_Channel_ID',\n",
    "                              'Ruta_SAK': 'Route_ID',\n",
    "                              'Cliente_ID': 'Client_ID',\n",
    "                              'Venta_uni_hoy': 'Sales_unit_this_week',\n",
    "                              'Venta_hoy': 'Sales_this_week',\n",
    "                              'Dev_uni_proxima': 'Returns_unit_next_week',\n",
    "                              'Dev_proxima': 'Returns_next_week',\n",
    "                              'Demanda_uni_equil': 'adjusted_demand',\n",
    "                              'Producto_ID': 'Product_ID'})\n",
    "\n",
    "test = test.rename(columns={'Semana': 'Week_num',\n",
    "                            'Agencia_ID': 'Sales_Depot_ID',\n",
    "                            'Canal_ID': 'Sales_Channel_ID',\n",
    "                            'Ruta_SAK': 'Route_ID',\n",
    "                            'Cliente_ID': 'Client_ID',\n",
    "                            'Venta_uni_hoy': 'Sales_unit_this_week',\n",
    "                            'Venta_hoy': 'Sales_this_week',\n",
    "                            'Dev_uni_proxima': 'Returns_unit_next_week',\n",
    "                            'Dev_proxima': 'Returns_next_week',\n",
    "                            'Demanda_uni_equil': 'adjusted_demand',\n",
    "                            'Producto_ID': 'Product_ID'})\n",
    "\n",
    "\n",
    "\n",
    "#set a unique id for each sales depot id, sales channel id, route id, client, product combination (thanks Gemini)\n",
    "combined_df = pd.concat([train,test])\n",
    "combined_df['ID'] = combined_df.groupby(['Sales_Depot_ID', 'Sales_Channel_ID', 'Route_ID', 'Client_ID', 'Product_ID']).ngroup()\n",
    "\n",
    "#set a combined client ID, consisting of a unique sales depot ID, sales channel ID, route ID, and client ID\n",
    "combined_df['ccid'] = combined_df.groupby(['Sales_Depot_ID', 'Sales_Channel_ID', 'Route_ID', 'Client_ID']).ngroup()\n",
    "\n",
    "#set a combined product ID, consisting of a unique sales depot ID, sales channel ID, route ID, and product ID\n",
    "combined_df['cpid'] = combined_df.groupby(['Sales_Depot_ID', 'Sales_Channel_ID', 'Route_ID', 'Product_ID']).ngroup()\n",
    "\n",
    "train = combined_df.iloc[:len(train)].copy()\n",
    "test = combined_df.iloc[len(train):].copy()\n",
    "\n",
    "del combined_df\n",
    "\n",
    "\n",
    "train = train.drop(columns='id')\n",
    "train['adjusted_demand'] = train['adjusted_demand'].astype(int)\n",
    "train['adjusted_demand'] = np.log1p(train['adjusted_demand'])\n",
    "train = train.sort_values(by=['ID', 'Week_num']).reset_index(drop=True)\n",
    "\n",
    "test = test.drop(columns='adjusted_demand')\n",
    "test['id'] = test['id'].astype(int)\n",
    "test = test.sort_values(by=['ID', 'Week_num']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27885bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe of aggregate statistics for each client\n",
    "testagg = train[train['Week_num'] <= 8].sort_values(by=['ccid']).groupby(['ccid'], as_index=False).agg({'Product_ID':'nunique', 'adjusted_demand':['mean', 'median', 'min', 'max']})\n",
    "\n",
    "client_stats = pd.DataFrame()\n",
    "\n",
    "client_stats['ccid'] = testagg['ccid']\n",
    "client_stats['Products'] = testagg['Product_ID']['nunique']\n",
    "client_stats['adj_dem_mean'] = testagg['adjusted_demand']['mean'].round(2)\n",
    "client_stats['adj_dem_median'] = testagg['adjusted_demand']['median'].astype(int)\n",
    "client_stats['adj_dem_min'] = testagg['adjusted_demand']['min']\n",
    "client_stats['adj_dem_max'] = testagg['adjusted_demand']['max']\n",
    "\n",
    "del testagg\n",
    "\n",
    "#create a dataframe of aggregate statistics for each product\n",
    "testagg = train[train['Week_num'] <= 8].sort_values(by=['cpid']).groupby(['cpid'], as_index=False).agg({'Client_ID':'nunique', 'adjusted_demand':['mean', 'median', 'min', 'max']})\n",
    "\n",
    "product_stats =  pd.DataFrame()\n",
    "\n",
    "product_stats['cpid'] = testagg['cpid']\n",
    "product_stats['Clients'] = testagg['Client_ID']['nunique']\n",
    "product_stats['adj_dem_mean'] = testagg['adjusted_demand']['mean'].round(2)\n",
    "product_stats['adj_dem_median'] = testagg['adjusted_demand']['median'].astype(int)\n",
    "product_stats['adj_dem_min'] = testagg['adjusted_demand']['min']\n",
    "product_stats['adj_dem_max'] = testagg['adjusted_demand']['max']\n",
    "product_stats['median_pct'] = product_stats['adj_dem_median'].rank(pct=True, method='average')\n",
    "\n",
    "del testagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee474ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ccid, cpid means, medians and cpid median percentage into training data\n",
    "cidmapping = pd.Series(client_stats[client_stats['ccid'].isin(train['ccid'].unique().tolist())].set_index('ccid')['adj_dem_mean'], index=client_stats[client_stats['ccid'].isin(train['ccid'].unique().tolist())]['ccid']).to_dict()\n",
    "train['ccid_mean'] = train['ccid'].map(cidmapping)\n",
    "\n",
    "cidmapping = pd.Series(client_stats[client_stats['ccid'].isin(train['ccid'].unique().tolist())].set_index('ccid')['adj_dem_median'], index=client_stats[client_stats['ccid'].isin(train['ccid'].unique().tolist())]['ccid']).to_dict()\n",
    "train['ccid_median'] = train['ccid'].map(cidmapping)\n",
    "\n",
    "pidmapping = pd.Series(product_stats[product_stats['cpid'].isin(train['cpid'].unique().tolist())].set_index('cpid')['adj_dem_mean'], index=product_stats[product_stats['cpid'].isin(train['cpid'].unique().tolist())]['cpid']).to_dict()\n",
    "train['cpid_mean'] = train['cpid'].map(pidmapping)\n",
    "\n",
    "pidmapping = pd.Series(product_stats[product_stats['cpid'].isin(train['cpid'].unique().tolist())].set_index('cpid')['adj_dem_median'], index=product_stats[product_stats['cpid'].isin(train['cpid'].unique().tolist())]['cpid']).to_dict()\n",
    "train['cpid_median'] = train['cpid'].map(pidmapping)\n",
    "\n",
    "pidmapping = pd.Series(product_stats[product_stats['cpid'].isin(train['cpid'].unique().tolist())].set_index('cpid')['median_pct'], index=product_stats[product_stats['cpid'].isin(train['cpid'].unique().tolist())]['cpid']).to_dict()\n",
    "train['cpid_median_pct'] = train['cpid'].map(pidmapping).round(3)\n",
    "\n",
    "\n",
    "# get total number of different products purchased by each client\n",
    "# get total number of clients \n",
    "\n",
    "del cidmapping, pidmapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d434ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fraction of IDs to sample\n",
    "fraction = 0.2\n",
    "\n",
    "# Calculate the number of IDs to sample\n",
    "unique_ids = train['ID'].unique()\n",
    "sample_size = int(len(unique_ids) * fraction)\n",
    "\n",
    "# Choose a random sample of IDs\n",
    "sampled_ids = np.random.choice(unique_ids, size=sample_size, replace=False)\n",
    "\n",
    "# Filter the DataFrame to keep all rows with the sampled IDs\n",
    "train = train[train['ID'].isin(sampled_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b010b",
   "metadata": {},
   "source": [
    "Impute NaN week 9 values by using the best simple prediction based on weeks 3-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "435fb3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ccid</th>\n",
       "      <th>ccid_mean</th>\n",
       "      <th>ccid_median</th>\n",
       "      <th>cpid</th>\n",
       "      <th>cpid_mean</th>\n",
       "      <th>cpid_median</th>\n",
       "      <th>cpid_median_pct</th>\n",
       "      <th>cpid_in_train</th>\n",
       "      <th>ccid_in_train</th>\n",
       "      <th>adjusted_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.125548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.209305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.125548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.125548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.125548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279324</th>\n",
       "      <td>27752054</td>\n",
       "      <td>2285196</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131519</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.209305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279325</th>\n",
       "      <td>27752057</td>\n",
       "      <td>2285196</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131527</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.943051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279326</th>\n",
       "      <td>27752061</td>\n",
       "      <td>2285196</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279327</th>\n",
       "      <td>27752089</td>\n",
       "      <td>2285202</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131541</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.125548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279328</th>\n",
       "      <td>27752090</td>\n",
       "      <td>2285202</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131561</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.882</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.730264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5279329 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID     ccid  ccid_mean  ccid_median     cpid  cpid_mean  \\\n",
       "0               1        0       1.72          1.0        5       0.99   \n",
       "1               6        0       1.72          1.0       20       1.57   \n",
       "2              17        0       1.72          1.0       39       1.18   \n",
       "3              22        0       1.72          1.0       47       1.14   \n",
       "4              24        0       1.72          1.0       50       1.75   \n",
       "...           ...      ...        ...          ...      ...        ...   \n",
       "5279324  27752054  2285196       1.14          1.0  1131519       1.68   \n",
       "5279325  27752057  2285196       1.14          1.0  1131527       1.76   \n",
       "5279326  27752061  2285196       1.14          1.0  1131560        NaN   \n",
       "5279327  27752089  2285202       1.72          1.0  1131541       1.53   \n",
       "5279328  27752090  2285202       1.72          1.0  1131561       3.93   \n",
       "\n",
       "         cpid_median  cpid_median_pct  cpid_in_train  ccid_in_train  \\\n",
       "0                1.0            0.399           True           True   \n",
       "1                1.0            0.399           True           True   \n",
       "2                1.0            0.399           True           True   \n",
       "3                1.0            0.399           True           True   \n",
       "4                1.0            0.399           True           True   \n",
       "...              ...              ...            ...            ...   \n",
       "5279324          1.0            0.399           True           True   \n",
       "5279325          1.0            0.399           True           True   \n",
       "5279326          NaN              NaN          False           True   \n",
       "5279327          1.0            0.399           True           True   \n",
       "5279328          3.0            0.882           True           True   \n",
       "\n",
       "         adjusted_demand  \n",
       "0               1.125548  \n",
       "1               1.209305  \n",
       "2               1.125548  \n",
       "3               1.125548  \n",
       "4               1.125548  \n",
       "...                  ...  \n",
       "5279324         1.209305  \n",
       "5279325         0.943051  \n",
       "5279326         1.000000  \n",
       "5279327         1.125548  \n",
       "5279328         1.730264  \n",
       "\n",
       "[5279329 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wk8IDs = train[train['Week_num'] == 8]['ID'].unique().tolist()\n",
    "wk9IDs = train[train['Week_num'] == 9]['ID'].unique().tolist()\n",
    "wk8and9IDs = list(set(wk8IDs) & set(wk9IDs))\n",
    "\n",
    "iw9 = train[['ID', 'ccid', 'ccid_mean', 'ccid_median', 'cpid', 'cpid_mean', 'cpid_median', 'cpid_median_pct']].drop_duplicates(subset='ID', keep='first').reset_index(drop=True).copy(deep=True)\n",
    "\n",
    "\n",
    "\n",
    "# are the cpid, ccids in the training data?\n",
    "iw9.loc[:, 'cpid_in_train'] = iw9['cpid'].isin(train[train['Week_num'] <= 8]['cpid'].unique().tolist())\n",
    "iw9.loc[:, 'ccid_in_train'] = iw9['ccid'].isin(train[train['Week_num'] <= 8]['ccid'].unique().tolist())\n",
    "\n",
    "# initialize adjusted demand column\n",
    "iw9['adjusted_demand'] = np.zeros(len(iw9))\n",
    "\n",
    "# for ccid and cpid not in training data, set adjusted demand to 5\n",
    "iw9.loc[(iw9['cpid_in_train'] == False) & (iw9['ccid_in_train'] == False), 'adjusted_demand'] = np.log1p(5)\n",
    "\n",
    "# for cpid in training data and ccid not in training data, use cpid median\n",
    "iw9.loc[(iw9['ccid_in_train'] == False) & (iw9['cpid_in_train'] == True), 'adjusted_demand'] = iw9[(iw9['ccid_in_train'] == False) & (iw9['cpid_in_train'] == True)]['cpid_median']\n",
    "\n",
    "# for ccid in training data and cpid not in training data, use ccid median\n",
    "iw9.loc[(iw9['ccid_in_train'] == True) & (iw9['cpid_in_train'] == False), 'adjusted_demand'] = iw9[(iw9['ccid_in_train'] == True) & (iw9['cpid_in_train'] == False)]['ccid_median']\n",
    "\n",
    "# for ccid, cpid in training data, use (0.5 + (cpid median pct)) * (0.65 * (ccid median) + (1-0.65) * (ccid mean))\n",
    "iw9.loc[(iw9['ccid_in_train'] == True) & (iw9['cpid_in_train'] == True), 'adjusted_demand'] = (0.5 + iw9[(iw9['ccid_in_train'] == True) & (iw9['cpid_in_train'] == True)]['cpid_median_pct'])*(0.65*iw9[(iw9['ccid_in_train'] == True) & (iw9['cpid_in_train'] == True)]['ccid_median'] + (1-0.65)*iw9[(iw9['ccid_in_train'] == True) & (iw9['cpid_in_train'] == True)]['ccid_mean'])\n",
    "\n",
    "\n",
    "\n",
    "# override with linear regression predicted adjusted demand for the IDs that have week 9 data\n",
    "\n",
    "\n",
    "# only use data points (adjusted demand) if they appear in consecutive weeks, i.e. week 3 and week 4 or week 6 and week 7.\n",
    "conseq_col = train['Week_num'].diff().dropna().astype(int)\n",
    "conseq_col.loc[0] = 0\n",
    "conseq_col = conseq_col.sort_index()\n",
    "\n",
    "train['conseq_pts'] = conseq_col\n",
    "\n",
    "train['adj_dem_lag1'] = train['adjusted_demand'].shift(1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X=train[(train['conseq_pts'] == 1) & (train['Week_num'] <= 8)][['adj_dem_lag1']].values, y=train[(train['conseq_pts'] == 1) & (train['Week_num'] <= 8)][['adjusted_demand']].values)\n",
    "\n",
    "# get week 9 prediction\n",
    "iw9.loc[iw9['ID'].isin(wk8and9IDs), 'adjusted_demand'] = lr.predict(train[(train['Week_num'] == 8) & (train['ID'].isin(train[train['Week_num'] == 9]['ID'].unique().tolist()))][['adjusted_demand']].values)\n",
    "\n",
    "iw9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12d5c929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5902885740785169"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(np.expm1(train[train['Week_num'] == 9]['adjusted_demand']), np.expm1(iw9.loc[iw9['ID'].isin(wk9IDs), 'adjusted_demand']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96d27a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Client_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>ccid_mean</th>\n",
       "      <th>ccid_median</th>\n",
       "      <th>cpid_mean</th>\n",
       "      <th>cpid_median</th>\n",
       "      <th>Wk_6_dem</th>\n",
       "      <th>Wk_7_dem</th>\n",
       "      <th>Wk_8_dem</th>\n",
       "      <th>Wk_9_dem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15766</td>\n",
       "      <td>328</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>15766</td>\n",
       "      <td>5350</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>15766</td>\n",
       "      <td>30551</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>15766</td>\n",
       "      <td>30574</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Client_ID Product_ID  ccid_mean  ccid_median  cpid_mean  cpid_median  \\\n",
       "0   1     15766        328       1.72          1.0       0.99          1.0   \n",
       "1   6     15766       1240       1.72          1.0       1.57          1.0   \n",
       "2  17     15766       5350       1.72          1.0       1.18          1.0   \n",
       "3  22     15766      30551       1.72          1.0       1.14          1.0   \n",
       "4  24     15766      30574       1.72          1.0       1.75          1.0   \n",
       "\n",
       "   Wk_6_dem  Wk_7_dem  Wk_8_dem  Wk_9_dem  \n",
       "0       NaN       NaN       NaN       NaN  \n",
       "1       NaN  2.197225  1.098612  1.098612  \n",
       "2       NaN       NaN       NaN  1.098612  \n",
       "3       NaN       NaN       NaN       NaN  \n",
       "4   1.94591       NaN       NaN       NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training data based on ID in order to use lagged adjusted demand\n",
    "trainIDdf = pd.DataFrame()\n",
    "\n",
    "trainIDdf = train[['ID', 'Client_ID', 'Product_ID', 'ccid_mean', 'ccid_median', 'cpid_mean', 'cpid_median']].drop_duplicates(subset='ID', keep='first').reset_index(drop=True)\n",
    "\n",
    "# get adjusted demand for the week for each ID \n",
    "for j in [6,7,8,9]:\n",
    "    wkmap = pd.Series(train[train['Week_num'] == j].set_index('ID')['adjusted_demand'], index=train['ID'].unique()).to_dict()\n",
    "    trainIDdf[f'Wk_{j}_dem'] = trainIDdf['ID'].map(wkmap)\n",
    "\n",
    "trainIDdf['ID'] = trainIDdf['ID'].astype('category')\n",
    "trainIDdf['Client_ID'] = trainIDdf['Client_ID'].astype('category')\n",
    "trainIDdf['Product_ID'] = trainIDdf['Product_ID'].astype('category')\n",
    "\n",
    "trainIDdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "858823fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eblac\\AppData\\Local\\Temp\\ipykernel_16356\\255397869.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  trainIDdf['Wk_9_dem'].fillna(iw9['adjusted_demand'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>ccid_mean</th>\n",
       "      <th>ccid_median</th>\n",
       "      <th>cpid_mean</th>\n",
       "      <th>cpid_median</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15766</td>\n",
       "      <td>328</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15766</td>\n",
       "      <td>5350</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15766</td>\n",
       "      <td>30551</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15766</td>\n",
       "      <td>30574</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Client_ID Product_ID  ccid_mean  ccid_median  cpid_mean  cpid_median  \\\n",
       "0     15766        328       1.72          1.0       0.99          1.0   \n",
       "1     15766       1240       1.72          1.0       1.57          1.0   \n",
       "2     15766       5350       1.72          1.0       1.18          1.0   \n",
       "3     15766      30551       1.72          1.0       1.14          1.0   \n",
       "4     15766      30574       1.72          1.0       1.75          1.0   \n",
       "\n",
       "     lag_3     lag_2     lag_1  \n",
       "0      NaN       NaN       NaN  \n",
       "1      NaN  2.197225  1.098612  \n",
       "2      NaN       NaN       NaN  \n",
       "3      NaN       NaN       NaN  \n",
       "4  1.94591       NaN       NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = trainIDdf.iloc[:, 1:-1].copy(deep=True)\n",
    "\n",
    "trainIDdf['Wk_9_dem'].fillna(iw9['adjusted_demand'], inplace=True)\n",
    "y_train = trainIDdf.iloc[:, -1].copy(deep=True)\n",
    "\n",
    "# X_train.drop(['Wk_3_dem', 'Wk_4_dem','Wk_5_dem'], axis=1, inplace=True)\n",
    "X_train.rename(columns={'Wk_6_dem': 'lag_3', 'Wk_7_dem': 'lag_2', 'Wk_8_dem': 'lag_1'}, inplace=True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57634520",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f4cbcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:19:38] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:20:48] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:24:02] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:27:45] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.train({'max_depth': 8, 'eta': 0.1, 'objective': 'reg:squaredlogerror', 'tree_method': 'gpu_hist'}, dtrain, num_boost_round=25)\n",
    "model2 = xgb.train({'max_depth': 8, 'eta': 0.1, 'objective': 'reg:squaredlogerror', 'tree_method': 'gpu_hist'}, dtrain, num_boost_round=50)\n",
    "model3 = xgb.train({'max_depth': 8, 'eta': 0.1, 'objective': 'reg:squaredlogerror', 'tree_method': 'gpu_hist'}, dtrain, num_boost_round=75)\n",
    "model4 = xgb.train({'max_depth': 8, 'eta': 0.1, 'objective': 'reg:squaredlogerror', 'tree_method': 'gpu_hist'}, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f120aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:35:43] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1: 0.43978223552111045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:35:44] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model2: 0.3529093346430481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:35:45] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3: 0.34863421523396765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eblac\\anaconda3\\envs\\erdos_spring_2025\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:35:46] WARNING: D:\\bld\\xgboost-split_1737698232980\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model4: 0.34780341797203246\n"
     ]
    }
   ],
   "source": [
    "test_pred = model1.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model1:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))\n",
    "\n",
    "test_pred = model2.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model2:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))\n",
    "\n",
    "test_pred = model3.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model3:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))\n",
    "\n",
    "test_pred = model4.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model4:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b6d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.train({'max_depth': 4, 'eta': 0.1, 'objective': 'reg:squaredlogerror'}, dtrain, num_boost_round=50)\n",
    "model2 = xgb.train({'max_depth': 6, 'eta': 0.1, 'objective': 'reg:squaredlogerror'}, dtrain, num_boost_round=50)\n",
    "model3 = xgb.train({'max_depth': 8, 'eta': 0.1, 'objective': 'reg:squaredlogerror'}, dtrain, num_boost_round=50)\n",
    "model4 = xgb.train({'max_depth': 10, 'eta': 0.1, 'objective': 'reg:squaredlogerror'}, dtrain, num_boost_round=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d15c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1: 0.3685791404244987\n",
      "model2: 0.36017671060316475\n",
      "model3: 0.3543582304155013\n",
      "model4: 0.3497146206117892\n"
     ]
    }
   ],
   "source": [
    "test_pred = model1.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model1:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))\n",
    "\n",
    "test_pred = model2.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model2:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))\n",
    "\n",
    "test_pred = model3.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model3:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))\n",
    "\n",
    "test_pred = model4.predict(xgb.DMatrix(X_train, enable_categorical=True))\n",
    "test_pred[test_pred < 0] = 0\n",
    "\n",
    "print(\"model4:\", rmsle(np.expm1(test_pred), np.expm1(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27519efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ID</th>\n",
       "      <th>Week_num</th>\n",
       "      <th>Client_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>ccid_mean</th>\n",
       "      <th>ccid_median</th>\n",
       "      <th>cpid_mean</th>\n",
       "      <th>cpid_median</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6558101</th>\n",
       "      <td>0</td>\n",
       "      <td>25973294</td>\n",
       "      <td>11</td>\n",
       "      <td>4639078</td>\n",
       "      <td>35305</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5991443</th>\n",
       "      <td>1</td>\n",
       "      <td>23662849</td>\n",
       "      <td>11</td>\n",
       "      <td>4705135</td>\n",
       "      <td>1238</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398738</th>\n",
       "      <td>2</td>\n",
       "      <td>21257171</td>\n",
       "      <td>10</td>\n",
       "      <td>4549769</td>\n",
       "      <td>32940</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383046</th>\n",
       "      <td>3</td>\n",
       "      <td>5334985</td>\n",
       "      <td>11</td>\n",
       "      <td>4717855</td>\n",
       "      <td>43066</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110570</th>\n",
       "      <td>4</td>\n",
       "      <td>4150753</td>\n",
       "      <td>11</td>\n",
       "      <td>966351</td>\n",
       "      <td>1277</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        ID  Week_num Client_ID Product_ID  ccid_mean  ccid_median  \\\n",
       "6558101   0  25973294        11   4639078      35305       1.21          1.0   \n",
       "5991443   1  23662849        11   4705135       1238       1.32          1.0   \n",
       "5398738   2  21257171        10   4549769      32940       1.73          1.0   \n",
       "1383046   3   5334985        11   4717855      43066       1.05          0.0   \n",
       "1110570   4   4150753        11    966351       1277       1.68          1.0   \n",
       "\n",
       "         cpid_mean  cpid_median  lag_3     lag_2     lag_1  \n",
       "6558101       1.67          1.0    NaN       NaN       NaN  \n",
       "5991443       1.03          1.0    NaN       NaN       NaN  \n",
       "5398738       1.16          1.0    NaN  1.098612  1.098612  \n",
       "1383046       0.78          0.0    NaN       NaN       NaN  \n",
       "1110570        NaN          NaN    NaN       NaN       NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ccid, cpid means and medians into test data\n",
    "cidmapping = pd.Series(client_stats[client_stats['ccid'].isin(test['ccid'].unique().tolist())].set_index('ccid')['adj_dem_mean'], index=client_stats[client_stats['ccid'].isin(test['ccid'].unique().tolist())]['ccid']).to_dict()\n",
    "test['ccid_mean'] = test['ccid'].map(cidmapping)\n",
    "\n",
    "cidmapping = pd.Series(client_stats[client_stats['ccid'].isin(test['ccid'].unique().tolist())].set_index('ccid')['adj_dem_median'], index=client_stats[client_stats['ccid'].isin(test['ccid'].unique().tolist())]['ccid']).to_dict()\n",
    "test['ccid_median'] = test['ccid'].map(cidmapping)\n",
    "\n",
    "pidmapping = pd.Series(product_stats[product_stats['cpid'].isin(test['cpid'].unique().tolist())].set_index('cpid')['adj_dem_mean'], index=product_stats[product_stats['cpid'].isin(test['cpid'].unique().tolist())]['cpid']).to_dict()\n",
    "test['cpid_mean'] = test['cpid'].map(pidmapping)\n",
    "\n",
    "pidmapping = pd.Series(product_stats[product_stats['cpid'].isin(test['cpid'].unique().tolist())].set_index('cpid')['adj_dem_median'], index=product_stats[product_stats['cpid'].isin(test['cpid'].unique().tolist())]['cpid']).to_dict()\n",
    "test['cpid_median'] = test['cpid'].map(pidmapping)\n",
    "\n",
    "del cidmapping, pidmapping\n",
    "\n",
    "test = test[['id', 'ID', 'Week_num', 'Client_ID', 'Product_ID', 'ccid_mean', 'ccid_median', 'cpid_mean', 'cpid_median']].sort_values(by='id')\n",
    "\n",
    "\n",
    "# get adjusted demand from previous weeks\n",
    "lagmap = pd.Series(trainIDdf[['ID', 'Wk_7_dem']].set_index('ID')['Wk_7_dem'], index=trainIDdf['ID'].tolist()).to_dict()\n",
    "test['lag_3'] = test['ID'].map(lagmap)\n",
    "\n",
    "lagmap = pd.Series(trainIDdf[['ID', 'Wk_8_dem']].set_index('ID')['Wk_8_dem'], index=trainIDdf['ID'].tolist()).to_dict()\n",
    "test['lag_2'] = test['ID'].map(lagmap)\n",
    "\n",
    "lagmap = pd.Series(trainIDdf[['ID', 'Wk_9_dem']].set_index('ID')['Wk_9_dem'], index=trainIDdf['ID'].tolist()).to_dict()\n",
    "test['lag_1'] = test['ID'].map(lagmap)\n",
    "\n",
    "del lagmap\n",
    "\n",
    "\n",
    "test['Client_ID'] = test['Client_ID'].astype('category')\n",
    "test['Product_ID'] = test['Product_ID'].astype('category')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cec881d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ID</th>\n",
       "      <th>Week_num</th>\n",
       "      <th>Client_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>ccid_mean</th>\n",
       "      <th>ccid_median</th>\n",
       "      <th>cpid_mean</th>\n",
       "      <th>cpid_median</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>wk_10_pred_dem</th>\n",
       "      <th>wk_11_pred_dem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25973294</td>\n",
       "      <td>11</td>\n",
       "      <td>4639078</td>\n",
       "      <td>35305</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23662849</td>\n",
       "      <td>11</td>\n",
       "      <td>4705135</td>\n",
       "      <td>1238</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21257171</td>\n",
       "      <td>10</td>\n",
       "      <td>4549769</td>\n",
       "      <td>32940</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.11381</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5334985</td>\n",
       "      <td>11</td>\n",
       "      <td>4717855</td>\n",
       "      <td>43066</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4150753</td>\n",
       "      <td>11</td>\n",
       "      <td>966351</td>\n",
       "      <td>1277</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.304518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        ID  Week_num Client_ID Product_ID  ccid_mean  ccid_median  \\\n",
       "0   0  25973294        11   4639078      35305       1.21          1.0   \n",
       "1   1  23662849        11   4705135       1238       1.32          1.0   \n",
       "2   2  21257171        10   4549769      32940       1.73          1.0   \n",
       "3   3   5334985        11   4717855      43066       1.05          0.0   \n",
       "4   4   4150753        11    966351       1277       1.68          1.0   \n",
       "\n",
       "   cpid_mean  cpid_median  lag_3     lag_2     lag_1  wk_10_pred_dem  \\\n",
       "0       1.67          1.0    NaN       NaN       NaN             NaN   \n",
       "1       1.03          1.0    NaN       NaN       NaN             NaN   \n",
       "2       1.16          1.0    NaN  1.098612  1.098612         1.11381   \n",
       "3       0.78          0.0    NaN       NaN       NaN             NaN   \n",
       "4        NaN          NaN    NaN       NaN       NaN             NaN   \n",
       "\n",
       "   wk_11_pred_dem  \n",
       "0        1.003540  \n",
       "1        0.969618  \n",
       "2             NaN  \n",
       "3        0.294357  \n",
       "4        1.304518  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict week 10 data\n",
    "X_test_wk10 = xgb.DMatrix(test[test['Week_num'] == 10].iloc[:, 3:], enable_categorical=True)\n",
    "\n",
    "predictions_10 = model4.predict(X_test_wk10)\n",
    "\n",
    "\n",
    "# add week 10 prediction to test\n",
    "test['wk_10_pred_dem'] = np.nan\n",
    "test.loc[test['Week_num'] == 10, 'wk_10_pred_dem'] = predictions_10\n",
    "\n",
    "\n",
    "# predict week 11 data\n",
    "test_wk11 = test[test['Week_num'] == 11].copy(deep=True)\n",
    "\n",
    "test_wk11.drop(['lag_3'], axis=1, inplace=True)\n",
    "test_wk11.rename(columns={'lag_2': 'lag_3', 'lag_1': 'lag_2', 'wk_10_pred_dem': 'lag_1'}, inplace=True)\n",
    "\n",
    "X_test_wk11 = xgb.DMatrix(test_wk11.iloc[:, 3:], enable_categorical=True)\n",
    "\n",
    "predictions_11 = model4.predict(X_test_wk11)\n",
    "\n",
    "\n",
    "# add week 11 prediction to test\n",
    "test['wk_11_pred_dem'] = np.nan\n",
    "test.loc[test['Week_num'] == 11, 'wk_11_pred_dem'] = predictions_11\n",
    "\n",
    "\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc692ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.727920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.636937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.045942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.342263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.685913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Demanda_uni_equil\n",
       "0   0           1.727920\n",
       "1   1           1.636937\n",
       "2   2           2.045942\n",
       "3   3           0.342263\n",
       "4   4           2.685913"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = np.arange(len(test))\n",
    "submission['Demanda_uni_equil'] = test['wk_10_pred_dem'].combine_first(test['wk_11_pred_dem'])\n",
    "submission['Demanda_uni_equil'] = np.expm1(submission['Demanda_uni_equil'])\n",
    "submission.loc[submission['Demanda_uni_equil'] < 0, 'Demanda_uni_equil'] = 0\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a16946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"xgb_prediction_2_log_ss.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
