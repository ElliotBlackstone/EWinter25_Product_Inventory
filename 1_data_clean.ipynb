{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\amirh\\AppData\\Local\\Temp\\ipykernel_25308\\1493115961.py:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data_path = \"..\\product-inventory\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743257\n"
     ]
    }
   ],
   "source": [
    "#data set from kaggle: https://www.kaggle.com/competitions/grupo-bimbo-inventory-demand/data\n",
    "\n",
    "# load train.csv\n",
    "data_path = \"..\\product-inventory\"\n",
    "filename = os.path.join(data_path, \"grupo-bimbo-inventory-demand/train.csv.zip\")\n",
    "\n",
    "train = pd.read_csv(filename, \n",
    "                 usecols=['Semana', 'Producto_ID', 'Cliente_ID', 'Demanda_uni_equil'])\n",
    "\n",
    "# rename columns\n",
    "train = train.rename(columns={  'Semana': 'Week_num',\n",
    "                                'Cliente_ID': 'Client_ID',\n",
    "                                'Demanda_uni_equil': 'adjusted_demand',\n",
    "                                'Producto_ID': 'Product_ID'})\n",
    "# define client-product ID\n",
    "train['ID'] = train.groupby(['Client_ID', 'Product_ID']).ngroup()\n",
    "unique_ids = train['ID'].unique()\n",
    "\n",
    "# Define the fraction of IDs to sample\n",
    "fraction = 0.01  # sample 1% of the IDs\n",
    "\n",
    "# Calculate the number of IDs to sample\n",
    "sample_size = int(len(unique_ids) * fraction)\n",
    "\n",
    "# Choose a random sample of IDs\n",
    "sampled_ids = np.random.choice(unique_ids, size=sample_size, replace=False)\n",
    "\n",
    "# Filter the DataFrame to keep all rows with the sampled IDs\n",
    "train = train[train['ID'].isin(sampled_ids)]\n",
    "\n",
    "print(len(train))\n",
    "\n",
    "# calculate price\n",
    "# train['Price'] = train['sales_this_week']/train['sales_unit_this_week']\n",
    "# train['log_price'] = np.log(train['Price'])\n",
    "\n",
    "# dependent variable\n",
    "# train['log_adj_demand'] = np.log(train['adjusted_demand'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(by=['ID', 'Week_num']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin(df):\n",
    "    '''\n",
    "    Input\n",
    "        df: A dataframe of length at most 7, with column names 'Week_num', 'Client_ID', 'Product_ID', 'adjusted_demand', 'ID',\n",
    "        where 'ID' is the unique idenifier for client id and product id combinations.  The intended input is train[train['ID' == id]],\n",
    "        where id is an element of the list train['ID'].unique().\n",
    "\n",
    "    Outputs\n",
    "        new_df: If df has 'adjusted_demand' values for each week (3 through 9), new_df = df, i.e. nothing happens.\n",
    "\n",
    "                If df has missing 'adjusted_demand' values for any week, the 'adjusted_demand' for that week will be 0.\n",
    "    '''\n",
    "\n",
    "    # EB: I'm not sure if it matters, but does it need to be a deep copy?\n",
    "    new_df = df.copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "    week_list = new_df['Week_num'].unique().tolist()\n",
    "    missing_week_list = [x for x in [3,4,5,6,7,8,9] if x not in week_list]\n",
    "\n",
    "    for i in missing_week_list:\n",
    "        \n",
    "        #create new row in new_df with the floor of the average value of prev_value and next_value\n",
    "        new_df = pd.concat([new_df, pd.DataFrame({'Week_num': i,\n",
    "                                                  'Client_ID': new_df['Client_ID'].iloc[0],\n",
    "                                                  'Product_ID': new_df['Product_ID'].iloc[0],\n",
    "                                                  'adjusted_demand': 0,\n",
    "                                                  'ID': new_df['ID'].iloc[0]}, index=[i])]).sort_values(by=['Week_num']).reset_index(drop=True)\n",
    "        \n",
    "        #update week_list\n",
    "        week_list.append(i)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m uid_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(uid_list)):\n\u001b[0;32m      5\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(fillin(train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m uid_list[j]]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "uid_list = train['ID'].unique().tolist()\n",
    "\n",
    "for j in range(len(uid_list)):\n",
    "    dfs.append(fillin(train[train['ID'] == uid_list[j]]))\n",
    "\n",
    "new_train = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Estimation\n",
    "Let's write down the first regressions.\n",
    "1. $demand_{t}$ on $demand_{t-1}$\n",
    "2. $log(demand_{t})$ on $log(demand_{t-1})$\n",
    "3. $demand_{t} = demand_{t-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.groupby(['ID', 'Week_num'], as_index=False).agg({'adjusted_demand': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.groupby(by='ID', as_index=False).agg({'Week_num': 'first'}).rename(columns={'Week_num': 'first_week'})\n",
    "train = train.merge(right = df, how='left', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables\n",
    "Here I define new variables and modify the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirh\\.julia\\conda\\3\\envs\\erdos_spring_2025\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train['adj_demand_1'] = train['adjusted_demand'].shift(1)\n",
    "train['week_1'] = train['Week_num'].shift(1)\n",
    "train['adj_demand_1'] = train['adj_demand_1'].where(train['week_1']+1 == train['Week_num'], np.nan)\n",
    "train['y'] = np.log(train['adjusted_demand'])\n",
    "train['y'] = train['y'].replace([np.inf, -np.inf], np.nan)\n",
    "train['y_1'] = np.log(train['adj_demand_1'])\n",
    "train['y_1'] = train['y_1'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.90314417 17.70075184 12.09425018]\n"
     ]
    }
   ],
   "source": [
    "#cross-validation for linear regression\n",
    "# y = adjusted demand\n",
    "# x = lagged adjusted demand\n",
    "\n",
    "gap = 1\n",
    "min_week = train['Week_num'].min()\n",
    "max_week = train['Week_num'].max()\n",
    "\n",
    "n_folds = 4\n",
    "n_models = 3\n",
    "i = 0\n",
    "model_mse = np.zeros(shape=(n_folds, n_models))\n",
    "lr = LinearRegression()\n",
    "lr2 = LinearRegression()\n",
    "\n",
    "for week in range(min_week + gap + 1, max_week):\n",
    "\n",
    "    # model 1\n",
    "    train_wo_na = train.dropna(subset=['adj_demand_1', 'adjusted_demand'])\n",
    "    df_tt = train_wo_na[train_wo_na['Week_num'] < week]\n",
    "    df_ho = train_wo_na[train_wo_na['Week_num'] == week]\n",
    "\n",
    "    lr.fit(X=df_tt[['adj_demand_1']], y=df_tt['adjusted_demand'])\n",
    "    pred = lr.predict(X=df_ho[['adj_demand_1']])\n",
    "\n",
    "    model_mse[i, 0] = root_mean_squared_error(y_true = df_ho['adjusted_demand'], y_pred = pred)\n",
    "\n",
    "    # model 2\n",
    "    train_wo_na = train.dropna(subset=['y', 'y_1'])\n",
    "\n",
    "    df_tt = train_wo_na[train_wo_na['Week_num'] < week]\n",
    "    df_ho = train_wo_na[train_wo_na['Week_num'] == week]\n",
    "    lr2.fit(X=df_tt[['y_1']], y=df_tt['y'])\n",
    "    pred = np.exp(lr2.predict(X=df_ho[['y_1']]))\n",
    "\n",
    "    model_mse[i, 1] = root_mean_squared_error(y_true = np.exp(df_ho['y']), y_pred = pred)\n",
    "\n",
    "    #model 3\n",
    "    train_wo_na = train.dropna(subset=['adj_demand_1', 'adjusted_demand'])\n",
    "    df_tt = train_wo_na[train_wo_na['Week_num'] < week]\n",
    "    df_ho = train_wo_na[train_wo_na['Week_num'] == week]\n",
    "    pred = df_ho['adj_demand_1']\n",
    "\n",
    "    model_mse[i, 2] = root_mean_squared_error(y_true = df_ho['adjusted_demand'], y_pred = pred)\n",
    "\n",
    "    i += 1\n",
    "print(model_mse.mean(axis=0))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can expand this model to include missing clients\n",
    "* We can include longer lagged in the model\n",
    "* Auto ARIMA i.e. find out the right number of lags\n",
    "* We can use the average of the client's observations for prediction\n",
    "* Calculate autocorrelation\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Auto Regression\n",
    "\n",
    "<!-- https://en.wikipedia.org/wiki/Autoregressive_model#n-step-ahead_forecasting -->\n",
    "<!-- https://en.wikipedia.org/wiki/Autoregressive_model#Evaluating_the_quality_of_forecasts -->\n",
    "\n",
    "A potential regression is\n",
    "$y_t = y_{t-1} + x_{t-1}$\n",
    "\n",
    "where $x_{t-1}$ is total sales of OTHER goods/total sales of ALL goods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in kfold.split(train):\n",
    "#     print(\"TRAIN INDEX:\", train_index)\n",
    "#     print(\"TEST INDEX:\", test_index)\n",
    "#     print()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LinearRegression()\n",
    "# X = train[['Price']]\n",
    "# X = X.fillna(0)\n",
    "# y = train['Adjusted_demand']\n",
    "# lr.fit(X, y)\n",
    "\n",
    "# preds = lr.predict(X)\n",
    "# print(\"Coefficient\", lr.coef_ )\n",
    "# print(\"Intercept:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(x = train[['Price']], y = train['Adjusted_demand'], c = 'blue')\n",
    "# plt.scatter(x = train[['Price']], y = preds, c = 'red')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train[['log_Price']]\n",
    "# X = X.fillna(0)\n",
    "# y = train['log_adjusted_demand']\n",
    "# lr.fit(X,y)\n",
    "\n",
    "# preds = lr.predict(X)\n",
    "# print(\"Coefficient\", lr.coef_ )\n",
    "# print(\"Intercept:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(x = train[['log_Price']], y = train['log_adjusted_demand'], c = 'blue')\n",
    "# plt.scatter(x = train[['log_Price']], y = preds, c = 'red')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write down the first regression which includes price, week FE, and state FE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dummies = [col for col in train.columns if 'state_' in col]\n",
    "# week_dummies = [col for col in train.columns if 'week_' in col]\n",
    "# X = train[state_dummies + week_dummies + ['Price']]\n",
    "# X = X.fillna(0)\n",
    "# y = train['Adjusted_demand']\n",
    "# lr.fit(X, y)\n",
    "\n",
    "# preds = lr.predict(X)\n",
    "# lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dummies = [col for col in train.columns if 'state_' in col]\n",
    "# week_dummies = [col for col in train.columns if 'week_' in col]\n",
    "# X = train[state_dummies + week_dummies + ['log_Price']]\n",
    "# X = X.fillna(0)\n",
    "# y = train['log_adjusted_demand']\n",
    "# lr.fit(X, y)\n",
    "\n",
    "# preds = lr.predict(X)\n",
    "# lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(x = train[['log_Price']], y = train['log_adjusted_demand'], c = 'blue')\n",
    "# plt.scatter(x = train[['log_Price']], y = preds, c = 'red')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
