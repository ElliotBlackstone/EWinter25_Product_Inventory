{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\amirh\\AppData\\Local\\Temp\\ipykernel_1896\\2721839105.py:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data_path = \"..\\product-inventory\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74180464\n"
     ]
    }
   ],
   "source": [
    "#data set from kaggle: https://www.kaggle.com/competitions/grupo-bimbo-inventory-demand/data\n",
    "\n",
    "# load train.csv\n",
    "data_path = \"..\\product-inventory\"\n",
    "filename = os.path.join(data_path, \"grupo-bimbo-inventory-demand/train.csv.zip\")\n",
    "\n",
    "train = pd.read_csv(filename, \n",
    "                 usecols=['Semana', 'Producto_ID', 'Cliente_ID', 'Demanda_uni_equil'])\n",
    "\n",
    "# rename columns\n",
    "train = train.rename(columns={  'Semana': 'Week_num',\n",
    "                                'Cliente_ID': 'Client_ID',\n",
    "                                'Demanda_uni_equil': 'adjusted_demand',\n",
    "                                'Producto_ID': 'Product_ID'})\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates client-product-week observation -> take the average as adjusted demand\n",
    "train = train.groupby(['Client_ID', 'Product_ID', 'Week_num'], as_index=False).agg({'adjusted_demand': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Estimation\n",
    "\n",
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Data Created\n",
      "Training Data mergred with Imputed Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirh\\.julia\\conda\\3\\envs\\erdos_spring_2025\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\amirh\\.julia\\conda\\3\\envs\\erdos_spring_2025\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Imputed Data\n",
    "# Fill in the missing values of adjusted demand with average client-product demand.\n",
    "df_imputed = train.groupby(by=['Product_ID', 'Client_ID'], as_index=False).agg({'adjusted_demand': 'mean'})\n",
    "df_imputed = df_imputed.rename(columns={'adjusted_demand': 'mean_demand'})\n",
    "print('Imputed Data Created')\n",
    "\n",
    "# Define lagged demand in the training data\n",
    "train['adj_demand_1'] = train['adjusted_demand'].shift(1)\n",
    "train['week_1'] = train['Week_num'].shift(1)\n",
    "train = train.merge(right=df_imputed,\n",
    "                    how = 'left',\n",
    "                    on = ['Client_ID', 'Product_ID'])\n",
    "print('Training Data mergred with Imputed Data')\n",
    "train['adj_demand_1'] = train['adj_demand_1'].where(train['week_1'] + 1 == train['Week_num'], np.nan)\n",
    "train['adj_demand_1'] = train['adj_demand_1'].fillna(train['mean_demand'])\n",
    "train['adj_demand_1'] = train['adj_demand_1'].where(train['Week_num'] != 3, np.nan)\n",
    "train = train.drop(columns=['mean_demand', 'week_1'])\n",
    "\n",
    "\n",
    "# Define log demand and log lagged demand\n",
    "train['y'] = np.log(train['adjusted_demand'])\n",
    "train['y'] = train['y'].replace([np.inf, -np.inf], np.nan)\n",
    "train['y_1'] = np.log(train['adj_demand_1'])\n",
    "train['y_1'] = train['y_1'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['Week_num']==3,'y_1'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "1. $demand_{t}$ on $demand_{t-1}$\n",
    "2. $log(demand_{t})$ on $log(demand_{t-1})$\n",
    "3. $demand_{t} = demand_{t-1}$\n",
    "\n",
    "In all model, I drop observations where the outcome variable or the independent variables are missing after imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_log_error as rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross-validation for linear regression\n",
    "# # y = adjusted demand\n",
    "# # x = lagged adjusted demand\n",
    "\n",
    "# # def cross_val(train):\n",
    "# gap = 1\n",
    "# min_week = train['Week_num'].min()\n",
    "# max_week = train['Week_num'].max()\n",
    "# n_folds = 4\n",
    "# n_models = 3\n",
    "# i = 0\n",
    "# # model_mse = np.zeros(shape=(n_folds, n_models))\n",
    "# model_msle = np.zeros(shape=(n_folds, n_models))\n",
    "# lr = LinearRegression()\n",
    "# lr2 = LinearRegression()\n",
    "# for week in range(min_week + gap + 1, max_week):\n",
    "#     # model 1\n",
    "#     print('Model 1', i)\n",
    "#     train = train.dropna(subset=['adj_demand_1', 'adjusted_demand'])\n",
    "#     df_tt = train[train['Week_num'] < week]\n",
    "#     df_ho = train[train['Week_num'] == week]\n",
    "#     lr.fit(X=df_tt[['adj_demand_1']], y=df_tt['adjusted_demand'])\n",
    "#     pred = lr.predict(X=df_ho[['adj_demand_1']])\n",
    "#     # model_mse[i, 0] = root_mean_squared_error(y_true = df_ho['adjusted_demand'], y_pred = pred)\n",
    "#     model_msle[i, 0] = rmsle(y_true = df_ho['adjusted_demand'], y_pred = pred)\n",
    "\n",
    "#     #model 2\n",
    "#     print('Model 2', i)\n",
    "#     train = train.dropna(subset=['adj_demand_1', 'adjusted_demand'])\n",
    "#     df_tt = train[train['Week_num'] < week]\n",
    "#     df_ho = train[train['Week_num'] == week]\n",
    "#     pred = df_ho['adj_demand_1']\n",
    "#     # model_mse[i, 2] = root_mean_squared_error(y_true = df_ho['adjusted_demand'], y_pred = pred)\n",
    "#     model_msle[i, 1] = rmsle(y_true = df_ho['adjusted_demand'], y_pred = pred)\n",
    "    \n",
    "#     # model 3\n",
    "#     print('Model 3', i)\n",
    "#     train = train.dropna(subset=['y', 'y_1'])\n",
    "#     df_tt = train[train['Week_num'] < week]\n",
    "#     df_ho = train[train['Week_num'] == week]\n",
    "#     lr2.fit(X=df_tt[['y_1']], y=df_tt['y'])\n",
    "#     pred = np.exp(lr2.predict(X=df_ho[['y_1']]))\n",
    "#     # model_mse[i, 1] = root_mean_squared_error(y_true = np.exp(df_ho['y']), y_pred = pred)\n",
    "#     model_msle[i, 2] = rmsle(y_true = np.exp(df_ho['y']), y_pred = pred)\n",
    "#     i += 1\n",
    "# # print(model_mse.mean(axis=0))  \n",
    "# print(model_msle.mean(axis=0)) \n",
    "\n",
    "# # cross_val(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3 is the best performing model\n",
    "## Run the final model\n",
    "train = train.dropna(subset=['y', 'y_1'])\n",
    "\n",
    "# test data set\n",
    "# I impute the missing client-product demand in week 9\n",
    "# by using the average client-product demand in week 3-8\n",
    "# df_ho = train_wo_na.groupby(by=['Product_ID', 'Client_ID'], as_index=False).agg({'adjusted_demand': 'mean'})\n",
    "# df_ho['y_1'] = np.log(df_ho['adjusted_demand'])\n",
    "# df_ho['y_1'] = df_ho['y_1'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df_ho = train.loc[train['Week_num'] == 9, ['Client_ID', 'Product_ID', 'y_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X=train[['y_1']], y=train['y'])\n",
    "\n",
    "# predict the demand\n",
    "df_ho['pred'] = np.exp(lr.predict(X=df_ho[['y_1']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Client_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Week_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "adjusted_demand",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "adj_demand_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y_1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b106a223-d3b3-4039-a864-8e3918a04fcd",
       "rows": [
        [
         "4",
         "26",
         "4767",
         "7",
         "42",
         "42.0",
         "3.7376696182833684",
         "3.7376696182833684"
        ],
        [
         "5",
         "26",
         "4767",
         "8",
         "42",
         "42.0",
         "3.7376696182833684",
         "3.7376696182833684"
        ],
        [
         "6",
         "26",
         "30235",
         "9",
         "96",
         "42.0",
         "4.564348191467836",
         "3.7376696182833684"
        ],
        [
         "7",
         "26",
         "30314",
         "7",
         "48",
         "48.0",
         "3.871201010907891",
         "3.871201010907891"
        ],
        [
         "9",
         "26",
         "31393",
         "4",
         "16",
         "20.0",
         "2.772588722239781",
         "2.995732273553991"
        ],
        [
         "10",
         "26",
         "31393",
         "5",
         "15",
         "16.0",
         "2.70805020110221",
         "2.772588722239781"
        ],
        [
         "11",
         "26",
         "31393",
         "6",
         "15",
         "15.0",
         "2.70805020110221",
         "2.70805020110221"
        ],
        [
         "12",
         "26",
         "31393",
         "7",
         "18",
         "15.0",
         "2.8903717578961645",
         "2.70805020110221"
        ],
        [
         "13",
         "26",
         "31393",
         "8",
         "22",
         "18.0",
         "3.091042453358316",
         "2.8903717578961645"
        ],
        [
         "14",
         "26",
         "31393",
         "9",
         "13",
         "22.0",
         "2.5649493574615367",
         "3.091042453358316"
        ],
        [
         "15",
         "26",
         "31518",
         "4",
         "10",
         "10.0",
         "2.302585092994046",
         "2.302585092994046"
        ],
        [
         "17",
         "26",
         "32953",
         "6",
         "7",
         "7.0",
         "1.9459101490553132",
         "1.9459101490553132"
        ],
        [
         "19",
         "26",
         "32962",
         "9",
         "10",
         "6.5",
         "2.302585092994046",
         "1.8718021769015913"
        ],
        [
         "21",
         "26",
         "33246",
         "4",
         "30",
         "30.0",
         "3.4011973816621555",
         "3.4011973816621555"
        ],
        [
         "22",
         "26",
         "33246",
         "5",
         "10",
         "30.0",
         "2.302585092994046",
         "3.4011973816621555"
        ],
        [
         "23",
         "26",
         "33246",
         "6",
         "10",
         "10.0",
         "2.302585092994046",
         "2.302585092994046"
        ],
        [
         "24",
         "26",
         "33246",
         "7",
         "30",
         "10.0",
         "3.4011973816621555",
         "2.302585092994046"
        ],
        [
         "25",
         "26",
         "33643",
         "5",
         "24",
         "30.0",
         "3.1780538303479458",
         "3.4011973816621555"
        ],
        [
         "26",
         "26",
         "33643",
         "6",
         "36",
         "24.0",
         "3.58351893845611",
         "3.1780538303479458"
        ],
        [
         "28",
         "26",
         "34204",
         "4",
         "30",
         "43.0",
         "3.4011973816621555",
         "3.7612001156935624"
        ],
        [
         "29",
         "26",
         "34204",
         "5",
         "44",
         "30.0",
         "3.784189633918261",
         "3.4011973816621555"
        ],
        [
         "30",
         "26",
         "34204",
         "6",
         "34",
         "44.0",
         "3.5263605246161616",
         "3.784189633918261"
        ],
        [
         "31",
         "26",
         "34204",
         "7",
         "36",
         "34.0",
         "3.58351893845611",
         "3.5263605246161616"
        ],
        [
         "32",
         "26",
         "34204",
         "8",
         "45",
         "36.0",
         "3.8066624897703196",
         "3.58351893845611"
        ],
        [
         "33",
         "26",
         "34204",
         "9",
         "43",
         "45.0",
         "3.7612001156935624",
         "3.8066624897703196"
        ],
        [
         "35",
         "26",
         "34206",
         "4",
         "81",
         "120.0",
         "4.394449154672439",
         "4.787491742782046"
        ],
        [
         "36",
         "26",
         "34206",
         "5",
         "42",
         "81.0",
         "3.7376696182833684",
         "4.394449154672439"
        ],
        [
         "37",
         "26",
         "34206",
         "6",
         "69",
         "42.0",
         "4.23410650459726",
         "3.7376696182833684"
        ],
        [
         "38",
         "26",
         "34206",
         "7",
         "96",
         "69.0",
         "4.564348191467836",
         "4.23410650459726"
        ],
        [
         "39",
         "26",
         "34206",
         "8",
         "89",
         "96.0",
         "4.48863636973214",
         "4.564348191467836"
        ],
        [
         "40",
         "26",
         "34206",
         "9",
         "107",
         "89.0",
         "4.672828834461906",
         "4.48863636973214"
        ],
        [
         "42",
         "26",
         "34210",
         "4",
         "42",
         "17.0",
         "3.7376696182833684",
         "2.833213344056216"
        ],
        [
         "43",
         "26",
         "34210",
         "5",
         "43",
         "42.0",
         "3.7612001156935624",
         "3.7376696182833684"
        ],
        [
         "44",
         "26",
         "34210",
         "6",
         "32",
         "43.0",
         "3.4657359027997265",
         "3.7612001156935624"
        ],
        [
         "45",
         "26",
         "34210",
         "7",
         "30",
         "32.0",
         "3.4011973816621555",
         "3.4657359027997265"
        ],
        [
         "46",
         "26",
         "34210",
         "8",
         "39",
         "30.0",
         "3.6635616461296463",
         "3.4011973816621555"
        ],
        [
         "47",
         "26",
         "34210",
         "9",
         "39",
         "39.0",
         "3.6635616461296463",
         "3.6635616461296463"
        ],
        [
         "49",
         "26",
         "34211",
         "4",
         "37",
         "42.0",
         "3.6109179126442243",
         "3.7376696182833684"
        ],
        [
         "50",
         "26",
         "34211",
         "5",
         "31",
         "37.0",
         "3.4339872044851463",
         "3.6109179126442243"
        ],
        [
         "51",
         "26",
         "34211",
         "6",
         "23",
         "31.0",
         "3.1354942159291497",
         "3.4339872044851463"
        ],
        [
         "52",
         "26",
         "34211",
         "7",
         "53",
         "23.0",
         "3.970291913552122",
         "3.1354942159291497"
        ],
        [
         "53",
         "26",
         "34211",
         "8",
         "34",
         "53.0",
         "3.5263605246161616",
         "3.970291913552122"
        ],
        [
         "54",
         "26",
         "34211",
         "9",
         "39",
         "34.0",
         "3.6635616461296463",
         "3.5263605246161616"
        ],
        [
         "55",
         "26",
         "34258",
         "4",
         "32",
         "14.0",
         "3.4657359027997265",
         "2.6390573296152584"
        ],
        [
         "56",
         "26",
         "34258",
         "7",
         "12",
         "14.0",
         "2.4849066497880004",
         "2.6390573296152584"
        ],
        [
         "60",
         "26",
         "34264",
         "4",
         "12",
         "20.0",
         "2.4849066497880004",
         "2.995732273553991"
        ],
        [
         "61",
         "26",
         "34264",
         "5",
         "10",
         "12.0",
         "2.302585092994046",
         "2.4849066497880004"
        ],
        [
         "62",
         "26",
         "34264",
         "6",
         "14",
         "10.0",
         "2.6390573296152584",
         "2.302585092994046"
        ],
        [
         "63",
         "26",
         "34264",
         "7",
         "7",
         "14.0",
         "1.9459101490553132",
         "2.6390573296152584"
        ],
        [
         "64",
         "26",
         "34264",
         "8",
         "20",
         "7.0",
         "2.995732273553991",
         "1.9459101490553132"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 61492910
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Week_num</th>\n",
       "      <th>adjusted_demand</th>\n",
       "      <th>adj_demand_1</th>\n",
       "      <th>y</th>\n",
       "      <th>y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>4767</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>3.737670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>4767</td>\n",
       "      <td>8</td>\n",
       "      <td>42</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>3.737670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>30235</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.564348</td>\n",
       "      <td>3.737670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>30314</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>3.871201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>31393</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74013015</th>\n",
       "      <td>2015152015</td>\n",
       "      <td>2665</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74013016</th>\n",
       "      <td>2015152015</td>\n",
       "      <td>3270</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.639057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74013018</th>\n",
       "      <td>2015152015</td>\n",
       "      <td>4270</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74013020</th>\n",
       "      <td>2015152015</td>\n",
       "      <td>4280</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74013022</th>\n",
       "      <td>2015152015</td>\n",
       "      <td>31717</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61492910 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Client_ID  Product_ID  Week_num  adjusted_demand  adj_demand_1  \\\n",
       "4                 26        4767         7               42          42.0   \n",
       "5                 26        4767         8               42          42.0   \n",
       "6                 26       30235         9               96          42.0   \n",
       "7                 26       30314         7               48          48.0   \n",
       "9                 26       31393         4               16          20.0   \n",
       "...              ...         ...       ...              ...           ...   \n",
       "74013015  2015152015        2665         9               10           7.0   \n",
       "74013016  2015152015        3270         8               14          14.0   \n",
       "74013018  2015152015        4270         6               10          10.0   \n",
       "74013020  2015152015        4280         9                8           6.0   \n",
       "74013022  2015152015       31717         9                3           4.0   \n",
       "\n",
       "                 y       y_1  \n",
       "4         3.737670  3.737670  \n",
       "5         3.737670  3.737670  \n",
       "6         4.564348  3.737670  \n",
       "7         3.871201  3.871201  \n",
       "9         2.772589  2.995732  \n",
       "...            ...       ...  \n",
       "74013015  2.302585  1.945910  \n",
       "74013016  2.639057  2.639057  \n",
       "74013018  2.302585  2.302585  \n",
       "74013020  2.079442  1.791759  \n",
       "74013022  1.098612  1.386294  \n",
       "\n",
       "[61492910 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Test Data\n",
    "Let's merge the prediction value with the test data based on `Product_ID` and `Client_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\amirh\\AppData\\Local\\Temp\\ipykernel_1896\\3137163994.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data_path = \"..\\product-inventory\"\n"
     ]
    }
   ],
   "source": [
    "# load test.csv\n",
    "data_path = \"..\\product-inventory\"\n",
    "filename = os.path.join(data_path, \"grupo-bimbo-inventory-demand/test.csv.zip\")\n",
    "\n",
    "test = pd.read_csv(filename, \n",
    "                 usecols=['id', 'Semana', 'Producto_ID', 'Cliente_ID'])\n",
    "# \n",
    "# rename columns\n",
    "test = test.rename(columns={'Semana': 'Week_num',\n",
    "                            'Cliente_ID': 'Client_ID',\n",
    "                            'Producto_ID': 'Product_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['id','Client_ID', 'Product_ID', 'Week_num']].merge(right=df_ho[['Client_ID', 'Product_ID', 'pred']], \n",
    "                                                                how='left', \n",
    "                                                                on=['Client_ID', 'Product_ID'])\n",
    "test = test.sort_values(by=['Client_ID', 'Product_ID', 'Week_num']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Client_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Week_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pred",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "07d628cf-37f9-4d35-ae23-4c21bf096ca0",
       "rows": [
        [
         "0",
         "1569352",
         "26",
         "31518",
         "10",
         null
        ],
        [
         "1",
         "4728674",
         "26",
         "31520",
         "11",
         null
        ],
        [
         "2",
         "1547831",
         "26",
         "34206",
         "11",
         "49.97113516388574"
        ],
        [
         "3",
         "6667200",
         "26",
         "34210",
         "10",
         "25.353573765850683"
        ],
        [
         "4",
         "1592616",
         "26",
         "34785",
         "10",
         "9.617805540883145"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Client_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Week_num</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1569352</td>\n",
       "      <td>26</td>\n",
       "      <td>31518</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4728674</td>\n",
       "      <td>26</td>\n",
       "      <td>31520</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1547831</td>\n",
       "      <td>26</td>\n",
       "      <td>34206</td>\n",
       "      <td>11</td>\n",
       "      <td>49.971135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6667200</td>\n",
       "      <td>26</td>\n",
       "      <td>34210</td>\n",
       "      <td>10</td>\n",
       "      <td>25.353574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1592616</td>\n",
       "      <td>26</td>\n",
       "      <td>34785</td>\n",
       "      <td>10</td>\n",
       "      <td>9.617806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Client_ID  Product_ID  Week_num       pred\n",
       "0  1569352         26       31518        10        NaN\n",
       "1  4728674         26       31520        11        NaN\n",
       "2  1547831         26       34206        11  49.971135\n",
       "3  6667200         26       34210        10  25.353574\n",
       "4  1592616         26       34785        10   9.617806"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What share of test sample is not in week 9 of the training sample?**\n",
    "\n",
    "42 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42490946531278845"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Prediction\n",
    "One of the main challenges is to predict the demand for the following cases:\n",
    "1. Existing Clients, New Products\n",
    "2. New Clients, Exisiting Products\n",
    "3. New Clients, New Prodcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load train.csv\n",
    "# data_path = \"..\\product-inventory\"\n",
    "# filename = os.path.join(data_path, \"grupo-bimbo-inventory-demand/train.csv.zip\")\n",
    "\n",
    "# train = pd.read_csv(filename, \n",
    "#                  usecols=['Semana', 'Producto_ID', 'Cliente_ID', 'Demanda_uni_equil'])\n",
    "\n",
    "# # rename columns\n",
    "# train = train.rename(columns={  'Semana': 'Week_num',\n",
    "#                                 'Cliente_ID': 'Client_ID',\n",
    "#                                 'Demanda_uni_equil': 'adjusted_demand',\n",
    "#                                 'Producto_ID': 'Product_ID'})\n",
    "\n",
    "# # duplicates client-product-week observation -> take the average as adjusted demand\n",
    "# train = train.groupby(['Client_ID', 'Product_ID', 'Week_num'], as_index=False).agg({'adjusted_demand': 'sum'})\n",
    "\n",
    "# # load test.csv\n",
    "# # data_path = \"..\\product-inventory\"\n",
    "# # filename = os.path.join(data_path, \"grupo-bimbo-inventory-demand/test.csv.zip\")\n",
    "# # \n",
    "# # test = pd.read_csv(filename, \n",
    "#                 #  usecols=['id','Semana', 'Producto_ID', 'Cliente_ID'])\n",
    "\n",
    "# # rename columns\n",
    "# # test = test.rename(columns={'Semana': 'Week_num',\n",
    "#                             # 'Cliente_ID': 'Client_ID',\n",
    "#                             # 'Producto_ID': 'Product_ID'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of existing clients in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list of exisiting and new clients\n",
    "# testID = test['Client_ID'].unique().tolist()\n",
    "# trainID = train['Client_ID'].unique().tolist()\n",
    "# commonID = list(set(testID).intersection(set(trainID)))\n",
    "# newID = list(set(testID) - set(trainID))\n",
    "\n",
    "# print(len(newID)/len(test['Client_ID'].unique()))\n",
    "\n",
    "# print(len(test['Client_ID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of existing and new products in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # list of existing and new products\n",
    "# testPID = test['Product_ID'].unique().tolist()\n",
    "# trainPID = train['Product_ID'].unique().tolist()\n",
    "# commonPID = list(set(testPID).intersection(set(trainPID)))\n",
    "# newPID = list(set(testPID) - set(trainPID))\n",
    "\n",
    "# print(len(newPID)/len(test['Product_ID'].unique()))\n",
    "\n",
    "# print(len(test['Product_ID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = len(test)\n",
    "# l1 = len(test.loc[(test['Client_ID'].isin(commonID)) & (test['Product_ID'].isin(newPID))])\n",
    "# l2 = len(test.loc[(test['Client_ID'].isin(newID)) & (test['Product_ID'].isin(commonPID))])\n",
    "# l3 = len(test.loc[(test['Client_ID'].isin(newID)) & (test['Product_ID'].isin(newPID))])\n",
    "# l4 = len(test.loc[(test['Client_ID'].isin(commonID)) & (test['Product_ID'].isin(commonPID))])\n",
    "\n",
    "# print(l1/l, l2/l, l3/l, l4/l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Existing Products\n",
    "This case consists of two possible scanarios:\n",
    "* New Client\n",
    "* Existing Client but a new combo\n",
    "\n",
    "In both scenarios, the in-sample estimation can not predict the demand. We use the average product demand in weeks 3-9 as our prediction.\n",
    "In the 2nd scenario, our prediction model has some shortcomings. For example, our measure does not take into account that a client might have a low demand for a new product. On the other hand, if we use the client's average demand as our prediction, it does not take into account the variation in products' demand. As a first pass, we use 'average prodct demand' as the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of Missing Preiction: 0.0036663923039765255\n"
     ]
    }
   ],
   "source": [
    "# use product's average demand in week 3-9 as a prediction for the new client.\n",
    "# pred_1 contains existing product with new client, and a prediction for the client's demand.\n",
    "pred_1 = train.groupby('Product_ID', as_index=False).agg({'adjusted_demand': 'mean'})\n",
    "test = test.merge(right=pred_1, \n",
    "                  how='left', \n",
    "                  on='Product_ID')\n",
    "test['pred'] = test['pred'].fillna(test['adjusted_demand'])\n",
    "print('Share of Missing Preiction:', test['pred'].isna().mean())\n",
    "\n",
    "del pred_1\n",
    "test = test.drop(columns='adjusted_demand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Existing Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of Missing Preiction: 1.814479863631123e-05\n"
     ]
    }
   ],
   "source": [
    "# use client's average demand in week 3-9 as a prediction for new product.\n",
    "#pred_1 contains existing clients with new products, and a prediction for the product.\n",
    "pred_1 = train.groupby('Client_ID', as_index=False).agg({'adjusted_demand': 'mean'})\n",
    "test = test.merge(right=pred_1, \n",
    "                  how='left', \n",
    "                  on='Client_ID')\n",
    "\n",
    "test['pred'] = test['pred'].fillna(test['adjusted_demand'])\n",
    "print('Share of Missing Preiction:', test['pred'].isna().mean())\n",
    "\n",
    "del pred_1\n",
    "test = test.drop(columns='adjusted_demand')\n",
    "# WATCH OUT: This replaces missing values for existing clients and existing products with the client's average demand. \n",
    "# THEY SHOULD BE REPLACED WITH THE ACTUAL PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. New Clients, New Products\n",
    "The intersection of new clients and new product in the test data. Here the first guess is the average demand for all product across all weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of Missing Preiction: 0.0\n"
     ]
    }
   ],
   "source": [
    "test['pred'] = test['pred'].fillna(train['adjusted_demand'].mean())\n",
    "print('Share of Missing Preiction:', test['pred'].isna().mean())\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\amirh\\AppData\\Local\\Temp\\ipykernel_1896\\998299805.py:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data_path = \"..\\product-inventory\"\n"
     ]
    }
   ],
   "source": [
    "output = test[['id', 'pred']]\n",
    "output = output.rename(columns={'pred': 'Demanda_uni_equil'})\n",
    "\n",
    "data_path = \"..\\product-inventory\"\n",
    "filename = os.path.join(data_path, \"prediction_2.csv\")\n",
    "output.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Demanda_uni_equil'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leftover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\amirh\\AppData\\Local\\Temp\\ipykernel_23768\\556068690.py:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data_path = \"..\\product-inventory\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14843968\n"
     ]
    }
   ],
   "source": [
    "#data set from kaggle: https://www.kaggle.com/competitions/grupo-bimbo-inventory-demand/data\n",
    "\n",
    "# load train.csv\n",
    "data_path = \"..\\product-inventory\"\n",
    "filename = os.path.join(data_path, \"grupo-bimbo-inventory-demand/train.csv.zip\")\n",
    "\n",
    "train = pd.read_csv(filename, \n",
    "                 usecols=['Semana', 'Producto_ID', 'Cliente_ID', 'Demanda_uni_equil'])\n",
    "\n",
    "# rename columns\n",
    "train = train.rename(columns={  'Semana': 'Week_num',\n",
    "                                'Cliente_ID': 'Client_ID',\n",
    "                                'Demanda_uni_equil': 'adjusted_demand',\n",
    "                                'Producto_ID': 'Product_ID'})\n",
    "# define client-product ID\n",
    "train['ID'] = train.groupby(['Client_ID', 'Product_ID']).ngroup()\n",
    "unique_ids = train['ID'].unique()\n",
    "\n",
    "# Define the fraction of IDs to sample\n",
    "fraction = 0.2  # sample 10% of the IDs\n",
    "\n",
    "# Calculate the number of IDs to sample\n",
    "sample_size = int(len(unique_ids) * fraction)\n",
    "\n",
    "rng = np.random.default_rng(4325252122)\n",
    "\n",
    "# Choose a random sample of IDs\n",
    "sampled_ids = np.random.choice(unique_ids, size=sample_size, replace=False)\n",
    "\n",
    "# Filter the DataFrame to keep all rows with the sampled IDs\n",
    "train = train[train['ID'].isin(sampled_ids)]\n",
    "\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation Function\n",
    "This function imputes missing observations based on the firms' demand. In this case, I set all missing observations to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillin(df):\n",
    "    '''\n",
    "    Input\n",
    "        df: A dataframe of length at most 7, with column names 'Week_num', 'Client_ID', 'Product_ID', 'adjusted_demand', 'ID',\n",
    "        where 'ID' is the unique idenifier for client id and product id combinations.  The intended input is train[train['ID' == id]],\n",
    "        where id is an element of the list train['ID'].unique().\n",
    "\n",
    "    Outputs\n",
    "        new_df: If df has 'adjusted_demand' values for each week (3 through 9), new_df = df, i.e. nothing happens.\n",
    "\n",
    "                If df has missing 'adjusted_demand' values for any week, the 'adjusted_demand' for that week will be 0.\n",
    "    '''\n",
    "\n",
    "    # EB: I'm not sure if it matters, but does it need to be a deep copy?\n",
    "    new_df = df.copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "    week_list = new_df['Week_num'].unique().tolist()\n",
    "    missing_week_list = [x for x in [3,4,5,6,7,8,9] if x not in week_list]\n",
    "\n",
    "    for i in missing_week_list:\n",
    "        \n",
    "        #create new row in new_df with the floor of the average value of prev_value and next_value\n",
    "        new_df = pd.concat([new_df, pd.DataFrame({'Week_num': i,\n",
    "                                                  'Client_ID': new_df['Client_ID'].iloc[0],\n",
    "                                                  'Product_ID': new_df['Product_ID'].iloc[0],\n",
    "                                                  'adjusted_demand': 0,\n",
    "                                                  'ID': new_df['ID'].iloc[0]}, index=[i])]).sort_values(by=['Week_num']).reset_index(drop=True)\n",
    "        \n",
    "        #update week_list\n",
    "        week_list.append(i)\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to impute the data is to expand the `train` such as it incluldes all possible ID x Week combination. We'll impute the data a later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unq_week = pd.DataFrame({'Week_num': train['Week_num'].unique()})\n",
    "# unq_week = unq_week.sort_values(by='Week_num').reset_index(drop=True)\n",
    "# unq_id = pd.DataFrame({'ID': train['ID'].unique()})\n",
    "# unq_id = unq_id.sort_values(by='ID').reset_index(drop=True)\n",
    "# combo = unq_id.merge(unq_week, how='cross')\n",
    "# train = combo.merge(train, how='outer', on=['ID', 'Week_num'], sort=True)\n",
    "\n",
    "# del combo, unq_week, unq_id\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(0, 10, 0.5).reshape(-1,1)\n",
    "# y = lr2.predict(x)\n",
    "\n",
    "# plt.scatter(df_ho['y_1'], df_ho['y'])\n",
    "# plt.plot(x, y)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can expand this model to include missing clients\n",
    "* We can include longer lagged in the model\n",
    "* Auto ARIMA i.e. find out the right number of lags\n",
    "* We can use the average of the client's observations for prediction\n",
    "* Calculate autocorrelation\n",
    "* XGBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
